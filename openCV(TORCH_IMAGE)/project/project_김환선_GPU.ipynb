{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faec16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import koreanize_matplotlib \n",
    "from torchmetrics.classification import F1Score, BinaryF1Score, Accuracy\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim \n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Set device to GPU if available\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc30939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set Image Data paths\n",
    "TEST_IMG_DIR = \"./data/train/\"\n",
    "VAL_IMG_DIR = \"./data/Validation/\"\n",
    "\n",
    "# Compose Transformations\n",
    "transform = transforms.Compose(\n",
    "    [ \n",
    "        transforms.Resize(size=(256, 256)),\n",
    "        transforms.ToTensor(),                                      # Image Tensor로 변환\n",
    "        transforms.ColorJitter(),                                   # Image 색상 무작위 조정\n",
    "        transforms.RandomResizedCrop(size=(224, 224)),              # Image 무작위 자르고 크기조절 \n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load Datasets\n",
    "TRAINDS = ImageFolder(root=TEST_IMG_DIR, transform=transform)\n",
    "VALDS = ImageFolder(root=VAL_IMG_DIR, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d636081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Image Dataset 확인\n",
    "print(f\"[Image Dataset]\\n{TRAINDS}\")\n",
    "print(f'[classes] {TRAINDS.classes}, {TRAINDS.class_to_idx}')\n",
    "print(f'[Targets] {TRAINDS.targets}')\n",
    "print('[imgs]')\n",
    "for item in TRAINDS.imgs : print(item)\n",
    "\n",
    "# Fake/Real Counts\n",
    "FAKE, REAL = 0, 0\n",
    "for _ in TRAINDS.targets :\n",
    "    if _ == 0 :\n",
    "        FAKE += 1\n",
    "    elif _ == 1 :\n",
    "        REAL += 1\n",
    "print(f\"FAKE : {FAKE}개, REAL : {REAL}개\")\n",
    "\n",
    "# Total count of training targets\n",
    "print(f\"Total Training Samples: {len(TRAINDS.targets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataLoader with specified batch size\n",
    "BATCH_SIZE = 128\n",
    "TRAINDL = DataLoader(TRAINDS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "VALDL = DataLoader(VALDS, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load AlexNet model with pre-trained weights\n",
    "model = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 2)\n",
    "\n",
    "# Move the model to the selected device (GPU or CPU)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Display model summary\n",
    "summary(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a47776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set all parameters to require gradient computation\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Training setup\n",
    "EPOCH = 10\n",
    "LR = 0.001\n",
    "patience = 7\n",
    "reqLoss = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=patience, verbose=True)\n",
    "LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []]\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    score_total = 0.0\n",
    "    \n",
    "    for inputs, labels in TRAINDL:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)  # Move to device\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs[:, 1])\n",
    "\n",
    "        # Compute loss\n",
    "        loss = reqLoss(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate F1 Score\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        score = BinaryF1Score()(predictions, labels)\n",
    "        score_total += score.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Average loss and F1 score for training\n",
    "    avg_train_loss = running_loss / len(TRAINDL)\n",
    "    avg_train_score = score_total / len(TRAINDL)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_score_total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in VALDL:\n",
    "            val_inputs, val_labels = val_inputs.to(DEVICE), val_labels.to(DEVICE)  # Move to device\n",
    "            val_labels = val_labels.float()\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_outputs = torch.sigmoid(val_outputs[:, 1])\n",
    "\n",
    "            val_loss += reqLoss(val_outputs, val_labels).item()\n",
    "\n",
    "            val_predictions = (val_outputs > 0.5).float()\n",
    "            val_score = BinaryF1Score()(val_predictions, val_labels)\n",
    "            val_score_total += val_score.item()\n",
    "    \n",
    "    # Average validation loss and score\n",
    "    avg_val_loss = val_loss / len(VALDL)\n",
    "    avg_val_score = val_score_total / len(VALDL)\n",
    "\n",
    "    # Log results\n",
    "    LOSS_HISTORY[0].append(avg_train_loss)\n",
    "    LOSS_HISTORY[1].append(avg_val_loss)\n",
    "    SCORE_HISTORY[0].append(avg_train_score)\n",
    "    SCORE_HISTORY[1].append(avg_val_score)\n",
    "    \n",
    "    print(f'[{epoch}/{EPOCH}] [TRAIN] LOSS: {avg_train_loss:.4f}, SCORE: {avg_train_score:.4f}')\n",
    "    print(f'[VALID] LOSS: {avg_val_loss:.4f}, SCORE: {avg_val_score:.4f}')\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping check\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "        print(f\"Stopping early at epoch {epoch} due to no improvement!\")\n",
    "        break\n",
    "\n",
    "    # Save model if validation score improves\n",
    "    if len(SCORE_HISTORY[1]) == 1 or SCORE_HISTORY[1][-1] > max(SCORE_HISTORY[1][:-1]):\n",
    "        SAVE_PATH = './models/project/BCF/'\n",
    "        SAVE_FILE = SAVE_PATH + 'model_train_wb.pth'\n",
    "        SAVE_MODEL = SAVE_PATH + 'model_all.pth'\n",
    "\n",
    "        if not os.path.exists(SAVE_PATH):\n",
    "            os.makedirs(SAVE_PATH)\n",
    "\n",
    "        torch.save(model.state_dict(), SAVE_FILE)\n",
    "        torch.save(model, SAVE_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6784e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization of loss and F1 score\n",
    "def plot_loss(LOSS_HISTORY):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(LOSS_HISTORY[0], label='Train Loss', color='blue', marker='o')\n",
    "    plt.plot(LOSS_HISTORY[1], label='Validation Loss', color='orange', marker='o')\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_f1_score(SCORE_HISTORY):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(SCORE_HISTORY[0], label='Train F1 Score', color='blue', marker='o')\n",
    "    plt.plot(SCORE_HISTORY[1], label='Validation F1 Score', color='orange', marker='o')\n",
    "    plt.title(\"Train vs Validation F1 Score\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "plot_loss(LOSS_HISTORY)\n",
    "plot_f1_score(SCORE_HISTORY)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
