{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project\n",
    "- 낚시성 기사 탐지\n",
    "- data -> Fake : 낚시성 기사, Real : 일반 기사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Korpora import Korpora\n",
    "from tabulate import tabulate\n",
    "import json\n",
    "import os \n",
    "import torch\n",
    "from collections import Counter\n",
    "from konlpy.tag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 장치 사용\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"./data/Train/\"\n",
    "# TRAIN_DATA = \"./data/Train\"\n",
    "# VAL_DATA = \"./data/Validation\"\n",
    "\n",
    "label_list = os.listdir(TRAIN_PATH)\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m file_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      9\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     10\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(data, record_path\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msourceDataInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentenceInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    byte sequences.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    310\u001b[0m         IncrementalDecoder\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict = {'text': [], 'label': []}\n",
    "\n",
    "for label in label_list:\n",
    "    folder_path = os.path.join(TRAIN_PATH, label)\n",
    "    file_list = os.listdir(folder_path)\n",
    "    \n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        with open(file_path, encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.json_normalize(data, record_path=[\"sourceDataInfo\", \"sentenceInfo\"])\n",
    "            \n",
    "            full_article = ' '.join(df['sentenceContent'])\n",
    "            \n",
    "            dict['text'].append(full_article)\n",
    "            dict['label'].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>손목시계는 이제 시간을 알려주는 도구 이상의 의미를 갖고 있다.</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어떤 이에게는 신분과 지위를 상징하고, 또 다른 이에게는 패션과 개성을 상징한다.</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여기에 가난을 없애고 목마름을 해소시키며 암을 예방해준다면, 그리고 가격이 40달러...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 심플하고 기능적인 손목시계에 기부의 의미를 추가한 시계가 바로 페이스 워치(Fa...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>페이스 워치는 미국 시카고의 브랜딩 회사 Mirza Minds의 대표 Fam Mir...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>제3세계의 빈곤과 선진국의 경제발전을 다 경험한 Fam Mirza 대표는 세계의 빈...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fam Mirza 대표는 인스타그램, 페이스북, 트위터등을 통해 사람들의 감정에 그...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0                손목시계는 이제 시간을 알려주는 도구 이상의 의미를 갖고 있다.  Fake\n",
       "1      어떤 이에게는 신분과 지위를 상징하고, 또 다른 이에게는 패션과 개성을 상징한다.  Fake\n",
       "2  여기에 가난을 없애고 목마름을 해소시키며 암을 예방해준다면, 그리고 가격이 40달러...  Fake\n",
       "3  이 심플하고 기능적인 손목시계에 기부의 의미를 추가한 시계가 바로 페이스 워치(Fa...  Fake\n",
       "4  페이스 워치는 미국 시카고의 브랜딩 회사 Mirza Minds의 대표 Fam Mir...  Fake\n",
       "5  제3세계의 빈곤과 선진국의 경제발전을 다 경험한 Fam Mirza 대표는 세계의 빈...  Fake\n",
       "6  Fam Mirza 대표는 인스타그램, 페이스북, 트위터등을 통해 사람들의 감정에 그...  Fake"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = pd.DataFrame(dict)\n",
    "trainDF.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593705</th>\n",
       "      <td>김순남의 곡들은 천지윤의 해금과 박윤우의 기타에 여현우의 클라리넷이 합세한 트리오 ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593706</th>\n",
       "      <td>서양음악에 국악과 재즈가 어우러져 독특한 울림을 자아낸다.</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593707</th>\n",
       "      <td>윤이상의 곡들은 천지윤의 해금과 조윤성의 피아노가 때론 함께 노닐고, 때론 서로 겨...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593708</th>\n",
       "      <td>전통 악기에 재즈의 리듬감과 현대음악의 조성이 섞이면서 세련된 음색을 빚어낸다.</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593709</th>\n",
       "      <td>악기 두 대의 조촐한 편성이지만 조금도 단조롭지 않다.</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593710</th>\n",
       "      <td>천지윤은 협업 경험이 풍부한 국악인이다. ‘이날치’의 베이시스트 장영규와 국악그룹 ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593711</th>\n",
       "      <td>9일 오전엔 두 앨범에 참여한 박윤우, 여현우, 조윤성과 함께 크로스오버 가수 박현...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "593705  김순남의 곡들은 천지윤의 해금과 박윤우의 기타에 여현우의 클라리넷이 합세한 트리오 ...  Real\n",
       "593706                   서양음악에 국악과 재즈가 어우러져 독특한 울림을 자아낸다.  Real\n",
       "593707  윤이상의 곡들은 천지윤의 해금과 조윤성의 피아노가 때론 함께 노닐고, 때론 서로 겨...  Real\n",
       "593708       전통 악기에 재즈의 리듬감과 현대음악의 조성이 섞이면서 세련된 음색을 빚어낸다.  Real\n",
       "593709                     악기 두 대의 조촐한 편성이지만 조금도 단조롭지 않다.  Real\n",
       "593710  천지윤은 협업 경험이 풍부한 국악인이다. ‘이날치’의 베이시스트 장영규와 국악그룹 ...  Real\n",
       "593711  9일 오전엔 두 앨범에 참여한 박윤우, 여현우, 조윤성과 함께 크로스오버 가수 박현...  Real"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train, text data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 474969\n",
      "Test 데이터 개수: 118743\n",
      "총 Data 수 : 593712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = trainDF[['text']]\n",
    "y = trainDF['label']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 데이터 확인\n",
    "print(f\"Train 데이터 개수: {len(X_train)}\")\n",
    "print(f\"Test 데이터 개수: {len(X_test)}\")\n",
    "print(f\"총 Data 수 : {len(X_train) + len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구두점, 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구두점 제거 함수\n",
    "def remove_punctuation(text):\n",
    "    punc = string.punctuation\n",
    "    if text in punc :\n",
    "        text = text.replace(punc, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train 데이터에서 구두점 제거\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_punctuation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Test 데이터에서 구두점 제거\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mapply(remove_punctuation)\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[78], line 4\u001b[0m, in \u001b[0;36mremove_punctuation\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_punctuation\u001b[39m(text):\n\u001b[0;32m      3\u001b[0m     punc \u001b[38;5;241m=\u001b[39m string\u001b[38;5;241m.\u001b[39mpunctuation\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpunc\u001b[49m :\n\u001b[0;32m      5\u001b[0m         text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(punc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[1;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not Series"
     ]
    }
   ],
   "source": [
    "# Train 데이터에서 구두점 제거\n",
    "X_train = X_train.apply(remove_punctuation)\n",
    "\n",
    "# Test 데이터에서 구두점 제거\n",
    "X_test = X_test.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구두점 제거 후 Train 데이터 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536407</th>\n",
       "      <td>최고 시속 300㎞ 이상으로 달린 창사-광저우, 류저우-구이양 간 고속철과 구이양~...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147040</th>\n",
       "      <td>한편 토론자로 나선 김점용 시인( 주간)은 “미당의 기념사업을 철회할 경우 윤리적 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453530</th>\n",
       "      <td>에서 왕을 보필하는 최측근, 조 내관 역이 그의 몫이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14285</th>\n",
       "      <td>각각에 대해 경제통으로 꼽히는 중앙일보시사미디어 편집위원들이 분석기사를 쓰고, 해당...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385465</th>\n",
       "      <td>뱅쇼는 프랑스어로 ‘Em거운 와인’이라는 뜻으로 독일에서는 글루바인Gluhwien,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "536407  최고 시속 300㎞ 이상으로 달린 창사-광저우, 류저우-구이양 간 고속철과 구이양~...\n",
       "147040  한편 토론자로 나선 김점용 시인( 주간)은 “미당의 기념사업을 철회할 경우 윤리적 ...\n",
       "453530                    에서 왕을 보필하는 최측근, 조 내관 역이 그의 몫이다.\n",
       "14285   각각에 대해 경제통으로 꼽히는 중앙일보시사미디어 편집위원들이 분석기사를 쓰고, 해당...\n",
       "385465  뱅쇼는 프랑스어로 ‘Em거운 와인’이라는 뜻으로 독일에서는 글루바인Gluhwien,..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제거된 결과 확인\n",
    "print(\"구두점 제거 후 Train 데이터 샘플:\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구두점 제거 후 Test 데이터 샘플:\n",
      "                                                     text\n",
      "418800             이화학술원 해외 석좌교수인 그는 2007년부터 이화여대 강단에 섰다.\n",
      "389748                          즉 감염자 99.9%는 걸린 후 나은 셈이다.\n",
      "375766  심한 정계정맥류에서 고환의 정맥이 부어오르고 임파선이 커지며 주변조직을 압박하는 경...\n",
      "591316  1998년 파리 초연 이후 지난해 한국 공연을 통해 18년 만에 작품에 복귀한 71...\n",
      "140416         범행 뒤 역삼동 또다른 화장실에 머물렀던 범인은 추가 범행을 계획했던 걸까?\n"
     ]
    }
   ],
   "source": [
    "print(\"구두점 제거 후 Test 데이터 샘플:\")\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트 생성\n",
    "stop_path = \"./data/stop_words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['프\\n',\n",
       " '뗴\\n',\n",
       " '잠시\\n',\n",
       " '채\\n',\n",
       " '즉시\\n',\n",
       " '드\\n',\n",
       " '하도록시키다\\n',\n",
       " '제\\n',\n",
       " '하는바\\n',\n",
       " '쓰\\n',\n",
       " '으로써\\n',\n",
       " '연이서\\n',\n",
       " '삐\\n',\n",
       " '결론을 낼 수 있다\\n',\n",
       " '지만\\n',\n",
       " '조용히\\n',\n",
       " '보는데서\\n',\n",
       " 'ㅟ\\n',\n",
       " 'ㅘ\\n',\n",
       " '탸\\n',\n",
       " '깨\\n',\n",
       " '똬\\n',\n",
       " '여보세요\\n',\n",
       " '잇따라\\n',\n",
       " 'ㅐ\\n',\n",
       " '삼\\n',\n",
       " '거바\\n',\n",
       " '이 때문에\\n',\n",
       " '소생\\n',\n",
       " '쉿\\n',\n",
       " '함께\\n',\n",
       " '난\\n',\n",
       " '정도에 이르다\\n',\n",
       " '언제\\n',\n",
       " '괴\\n',\n",
       " '매번\\n',\n",
       " '하는 김에\\n',\n",
       " '거기\\n',\n",
       " '초\\n',\n",
       " '까\\n',\n",
       " '바꾸어말하자면\\n',\n",
       " '솨\\n',\n",
       " '처\\n',\n",
       " '꾸\\n',\n",
       " '까닭으로\\n',\n",
       " '그럼에도\\n',\n",
       " '아이참\\n',\n",
       " '곳\\n',\n",
       " '더욱더\\n',\n",
       " '그중에서\\n',\n",
       " '흥\\n',\n",
       " '양자\\n',\n",
       " '차\\n',\n",
       " 'ㅈ\\n',\n",
       " '라서\\n',\n",
       " '나\\n',\n",
       " '비로소\\n',\n",
       " '쐬\\n',\n",
       " '요만한걸\\n',\n",
       " '이 외에\\n',\n",
       " '허\\n',\n",
       " '하는 것도\\n',\n",
       " '겨\\n',\n",
       " '절대\\n',\n",
       " '지든지\\n',\n",
       " '하물며\\n',\n",
       " '요만한 것\\n',\n",
       " '좌\\n',\n",
       " '지말고\\n',\n",
       " '이리하여\\n',\n",
       " '좋아\\n',\n",
       " '이었다\\n',\n",
       " '하네요\\n',\n",
       " '따위\\n',\n",
       " '아하\\n',\n",
       " '할때\\n',\n",
       " '그렇지만\\n',\n",
       " '두\\n',\n",
       " '어떻게\\n',\n",
       " '내일\\n',\n",
       " '퐈\\n',\n",
       " '료\\n',\n",
       " '무엇때문에\\n',\n",
       " '종\\n',\n",
       " '게\\n',\n",
       " '버\\n',\n",
       " '하기에\\n',\n",
       " '하기 보다는\\n',\n",
       " '한켠으로는\\n',\n",
       " '시각\\n',\n",
       " '펴\\n',\n",
       " '만은 아니다\\n',\n",
       " '심지어\\n',\n",
       " '설\\n',\n",
       " '도달하다\\n',\n",
       " '퍽\\n',\n",
       " 'ㅒ\\n',\n",
       " '겹\\n',\n",
       " '어기여차\\n',\n",
       " '에도\\n',\n",
       " '트\\n',\n",
       " '타인\\n',\n",
       " '나왔는데\\n',\n",
       " '볘\\n',\n",
       " '퇴\\n',\n",
       " '세상에\\n',\n",
       " '외에도\\n',\n",
       " '서\\n',\n",
       " '당신들\\n',\n",
       " 'ㅁ\\n',\n",
       " '이와 반대로\\n',\n",
       " '어이\\n',\n",
       " '일단\\n',\n",
       " '이봐\\n',\n",
       " 'ㅛ\\n',\n",
       " '띠\\n',\n",
       " '어찌됐든\\n',\n",
       " '마저도\\n',\n",
       " '떼\\n',\n",
       " '뽜\\n',\n",
       " '책\\n',\n",
       " '톼\\n',\n",
       " '만\\n',\n",
       " '떠\\n',\n",
       " '할 수 있다\\n',\n",
       " '아무런\\n',\n",
       " '아무\\n',\n",
       " 'ㄹ\\n',\n",
       " '니\\n',\n",
       " '우선\\n',\n",
       " '정\\n',\n",
       " '튜\\n',\n",
       " '뜨\\n',\n",
       " '그위에\\n',\n",
       " '간\\n',\n",
       " '반대로\\n',\n",
       " '본대로\\n',\n",
       " '뻐\\n',\n",
       " '한데\\n',\n",
       " '월\\n',\n",
       " '기준으로\\n',\n",
       " '까악\\n',\n",
       " '끄\\n',\n",
       " '거\\n',\n",
       " '입각\\n',\n",
       " '례\\n',\n",
       " '땨\\n',\n",
       " '몇\\n',\n",
       " '시\\n',\n",
       " '아무데도\\n',\n",
       " '년\\n',\n",
       " '어찌 됐어\\n',\n",
       " '붜\\n',\n",
       " '하지 않도록\\n',\n",
       " '어째서\\n',\n",
       " '으로부터\\n',\n",
       " 'ㅑ\\n',\n",
       " '어떤 것\\n',\n",
       " '아\\n',\n",
       " '한 이유는\\n',\n",
       " '가령\\n',\n",
       " '하도록하다\\n',\n",
       " '어찌하든지\\n',\n",
       " '전자\\n',\n",
       " '하하\\n',\n",
       " '쀼\\n',\n",
       " '그러니까\\n',\n",
       " '팍\\n',\n",
       " '왜냐하면\\n',\n",
       " '할 지경이다\\n',\n",
       " '응\\n',\n",
       " '얼\\n',\n",
       " '타\\n',\n",
       " '취\\n',\n",
       " '바꾸어\\n',\n",
       " '되\\n',\n",
       " '각각\\n',\n",
       " '어느해\\n',\n",
       " '하든지\\n',\n",
       " '같\\n',\n",
       " '툭\\n',\n",
       " '헤\\n',\n",
       " '구체적으로\\n',\n",
       " '데\\n',\n",
       " '너무\\n',\n",
       " '여부\\n',\n",
       " '시작하여\\n',\n",
       " '부\\n',\n",
       " '쮸\\n',\n",
       " '설령\\n',\n",
       " '즈\\n',\n",
       " '쿼\\n',\n",
       " '엄\\n',\n",
       " '누가 알겠는가\\n',\n",
       " '오직\\n',\n",
       " '쭈\\n',\n",
       " '쀠\\n',\n",
       " '보드득\\n',\n",
       " '해\\n',\n",
       " '동시에\\n',\n",
       " '한편\\n',\n",
       " '어떤것\\n',\n",
       " '에 달려 있다\\n',\n",
       " '우에 종합한 것과 같이\\n',\n",
       " '쫘\\n',\n",
       " '갖고 말하자면\\n',\n",
       " '해도좋다\\n',\n",
       " '하기는 한데\\n',\n",
       " '우리\\n',\n",
       " '이지만\\n',\n",
       " '칠\\n',\n",
       " '막\\n',\n",
       " '싸\\n',\n",
       " '답\\n',\n",
       " 'ㅖ\\n',\n",
       " '퓨\\n',\n",
       " '사\\n',\n",
       " '죠\\n',\n",
       " '따지지 않다\\n',\n",
       " '대해서\\n',\n",
       " '스\\n',\n",
       " '이외에도\\n',\n",
       " '받은\\n',\n",
       " '라\\n',\n",
       " '하고도\\n',\n",
       " 'ㅔ\\n',\n",
       " '일\\n',\n",
       " '도록\\n',\n",
       " '갔나\\n',\n",
       " '각\\n',\n",
       " '뵈\\n',\n",
       " '아슬아슬한\\n',\n",
       " '그치지 않다\\n',\n",
       " '둘\\n',\n",
       " '쿠\\n',\n",
       " '모두\\n',\n",
       " '하고 있다\\n',\n",
       " '바꿔 말하면\\n',\n",
       " '더욱이는\\n',\n",
       " '꺄\\n',\n",
       " '하지\\n',\n",
       " '팔\\n',\n",
       " '으\\n',\n",
       " '때\\n',\n",
       " '툐\\n',\n",
       " '전후\\n',\n",
       " '오자마자\\n',\n",
       " '틈타\\n',\n",
       " '뿨\\n',\n",
       " 'ㅎ\\n',\n",
       " '코\\n',\n",
       " '듀\\n',\n",
       " '아래윗\\n',\n",
       " '한마디\\n',\n",
       " '저사람\\n',\n",
       " '저\\n',\n",
       " '비록\\n',\n",
       " '개의치 않고\\n',\n",
       " '괜\\n',\n",
       " '대해\\n',\n",
       " '바꾸어서 말하면\\n',\n",
       " '첫번째로\\n',\n",
       " '시초에\\n',\n",
       " '할만하다\\n',\n",
       " '뤼\\n',\n",
       " '뀌\\n',\n",
       " '어랏\\n',\n",
       " '덜\\n',\n",
       " '다시말하면\\n',\n",
       " '체\\n',\n",
       " '햐\\n',\n",
       " '남들\\n',\n",
       " '이리\\n',\n",
       " '슈\\n',\n",
       " '둬\\n',\n",
       " '먀\\n',\n",
       " '이와 같은\\n',\n",
       " '놀라다\\n',\n",
       " '쪄\\n',\n",
       " '또는\\n',\n",
       " '커\\n',\n",
       " '한다면\\n',\n",
       " '헐떡헐떡\\n',\n",
       " '해봐요\\n',\n",
       " '만약\\n',\n",
       " '쁘\\n',\n",
       " '그렇지\\n',\n",
       " '하는것이 낫다\\n',\n",
       " '다시 말하면\\n',\n",
       " '샤\\n',\n",
       " '그리고\\n',\n",
       " '이유만으로\\n',\n",
       " '쿵\\n',\n",
       " '그렇지 않으면\\n',\n",
       " '이렇게되면\\n',\n",
       " '케\\n',\n",
       " '휘\\n',\n",
       " '여러분\\n',\n",
       " '하기는한데\\n',\n",
       " '쎠\\n',\n",
       " '화\\n',\n",
       " '저희\\n',\n",
       " '하게 하다\\n',\n",
       " '생각한대로\\n',\n",
       " '셋\\n',\n",
       " '점에서 보아\\n',\n",
       " '동안\\n',\n",
       " '탕탕\\n',\n",
       " '할줄알다\\n',\n",
       " '즈음하여\\n',\n",
       " '한테\\n',\n",
       " '뀨\\n',\n",
       " '퉈\\n',\n",
       " '하지만\\n',\n",
       " '습니다\\n',\n",
       " '바꾸어 말하면\\n',\n",
       " '이사람\\n',\n",
       " '꿔\\n',\n",
       " '따라\\n',\n",
       " '다음\\n',\n",
       " '쭤\\n',\n",
       " '더불어\\n',\n",
       " '어느쪽\\n',\n",
       " '주\\n',\n",
       " '오호\\n',\n",
       " '늬\\n',\n",
       " '어떻해\\n',\n",
       " '시작\\n',\n",
       " '부탁\\n',\n",
       " '다만\\n',\n",
       " '기점으로\\n',\n",
       " '총적으로 보면\\n',\n",
       " '방\\n',\n",
       " '심\\n',\n",
       " '쑤\\n',\n",
       " '수\\n',\n",
       " '헉헉\\n',\n",
       " '어느\\n',\n",
       " '반면\\n',\n",
       " '뿐만아니라\\n',\n",
       " '이용하여\\n',\n",
       " '이에요\\n',\n",
       " '테\\n',\n",
       " '바로\\n',\n",
       " '비슷하다\\n',\n",
       " '뎨\\n',\n",
       " '토하다\\n',\n",
       " '여기\\n',\n",
       " '자신\\n',\n",
       " '추\\n',\n",
       " '름\\n',\n",
       " '졸졸\\n',\n",
       " '얼마만큼\\n',\n",
       " '해도 좋다\\n',\n",
       " '밖에 안 된다\\n',\n",
       " '게우다\\n',\n",
       " '전\\n',\n",
       " '듸\\n',\n",
       " '등등\\n',\n",
       " '때문에\\n',\n",
       " '부류의 사람들\\n',\n",
       " '근거로\\n',\n",
       " '그래도\\n',\n",
       " '영\\n',\n",
       " '그렇지않으면\\n',\n",
       " '이라면\\n',\n",
       " '갖고말하자면\\n',\n",
       " '하게될것이다\\n',\n",
       " '어찌하여\\n',\n",
       " '하기보다는\\n',\n",
       " '보\\n',\n",
       " 'ㄸ\\n',\n",
       " '최\\n',\n",
       " '규\\n',\n",
       " '하고\\n',\n",
       " '할수있어\\n',\n",
       " '뷔\\n',\n",
       " '하겠는가\\n',\n",
       " '관련이 있다\\n',\n",
       " '토\\n',\n",
       " '어쩌면\\n',\n",
       " '상태\\n',\n",
       " '쿄\\n',\n",
       " '저쪽\\n',\n",
       " '뒤\\n',\n",
       " '믜\\n',\n",
       " '그때\\n',\n",
       " '기대여\\n',\n",
       " '라는\\n',\n",
       " '공\\n',\n",
       " '알\\n',\n",
       " '분명\\n',\n",
       " '할 줄 안다\\n',\n",
       " '아니라면\\n',\n",
       " '이분\\n',\n",
       " '계\\n',\n",
       " '요컨대\\n',\n",
       " '있다\\n',\n",
       " '하면서\\n',\n",
       " '해도된다\\n',\n",
       " '좍좍\\n',\n",
       " '쳬\\n',\n",
       " '여덟\\n',\n",
       " '동\\n',\n",
       " '쥐\\n',\n",
       " '가까스로\\n',\n",
       " '뾔\\n',\n",
       " '여차\\n',\n",
       " '벼\\n',\n",
       " '도\\n',\n",
       " '기\\n',\n",
       " '사람\\n',\n",
       " '루\\n',\n",
       " '저러나\\n',\n",
       " '것과 같이\\n',\n",
       " '쇼\\n',\n",
       " '혹시\\n',\n",
       " '느\\n',\n",
       " '밖에\\n',\n",
       " '어제\\n',\n",
       " '춰\\n',\n",
       " '그런 까닭에\\n',\n",
       " '캬\\n',\n",
       " '는\\n',\n",
       " '감\\n',\n",
       " '와우\\n',\n",
       " '운운\\n',\n",
       " '녀\\n',\n",
       " '하는 편이 낫다\\n',\n",
       " '알았어\\n',\n",
       " '마\\n',\n",
       " '어떤 것들\\n',\n",
       " '무슨\\n',\n",
       " '뚜\\n',\n",
       " '장\\n',\n",
       " '아이야\\n',\n",
       " '하면된다\\n',\n",
       " '무릎 쓰고\\n',\n",
       " '각종\\n',\n",
       " '끼익\\n',\n",
       " '엉엉\\n',\n",
       " '쬬\\n',\n",
       " '텨\\n',\n",
       " '여전히\\n',\n",
       " '하겠다고\\n',\n",
       " '비교적\\n',\n",
       " '하기 위하여\\n',\n",
       " '다섯\\n',\n",
       " '뮈\\n',\n",
       " '갑\\n',\n",
       " '챠\\n',\n",
       " '어느 해\\n',\n",
       " '앗\\n',\n",
       " '이천구\\n',\n",
       " '려\\n',\n",
       " '두번째로\\n',\n",
       " '라도\\n',\n",
       " '주저하지 않고\\n',\n",
       " '륙\\n',\n",
       " '너\\n',\n",
       " '혹은\\n',\n",
       " '한\\n',\n",
       " '븨\\n',\n",
       " '만이 아니다\\n',\n",
       " '넷\\n',\n",
       " '뿐만 아니라\\n',\n",
       " '임에 틀림없다\\n',\n",
       " '위해\\n',\n",
       " '히\\n',\n",
       " '만 못하다\\n',\n",
       " '비추어 보아\\n',\n",
       " '결국\\n',\n",
       " '끙끙\\n',\n",
       " '다시 말하자면\\n',\n",
       " '얼마간\\n',\n",
       " '빼\\n',\n",
       " '관계가 있다\\n',\n",
       " '패\\n',\n",
       " '쪠\\n',\n",
       " '뉘\\n',\n",
       " '랑\\n',\n",
       " '아이\\n',\n",
       " '날\\n',\n",
       " '그들\\n',\n",
       " '된이상\\n',\n",
       " '이와 같다\\n',\n",
       " '왜\\n',\n",
       " '당\\n',\n",
       " 'ㅝ\\n',\n",
       " '리\\n',\n",
       " '뇌\\n',\n",
       " '을\\n',\n",
       " '에게\\n',\n",
       " '딩동\\n',\n",
       " '위하여\\n',\n",
       " '제외하고\\n',\n",
       " '및\\n',\n",
       " 'ㅣ\\n',\n",
       " '야호\\n',\n",
       " '그렇지 않다면\\n',\n",
       " '백\\n',\n",
       " '얼마큼\\n',\n",
       " '래\\n',\n",
       " '쒸\\n',\n",
       " '싀\\n',\n",
       " '이건\\n',\n",
       " '오르다\\n',\n",
       " '로써\\n',\n",
       " '이젠\\n',\n",
       " '이천육\\n',\n",
       " '중의 하나\\n',\n",
       " '의해서\\n',\n",
       " '해야한다\\n',\n",
       " '이야기\\n',\n",
       " '으로\\n',\n",
       " '휴\\n',\n",
       " '퍼\\n',\n",
       " '문\\n',\n",
       " '이제\\n',\n",
       " '이렇게 말하자면\\n',\n",
       " '쪼\\n',\n",
       " '한참\\n',\n",
       " '관\\n',\n",
       " '져\\n',\n",
       " '내\\n',\n",
       " '천천히\\n',\n",
       " '다음으로\\n',\n",
       " '아울러\\n',\n",
       " '픠\\n',\n",
       " '아아\\n',\n",
       " '여섯\\n',\n",
       " '오로지\\n',\n",
       " 'ㅇ\\n',\n",
       " '와 같은 사람들\\n',\n",
       " '틔\\n',\n",
       " '할지라도\\n',\n",
       " '푸\\n',\n",
       " '쏴\\n',\n",
       " '우리들\\n',\n",
       " '어느때\\n',\n",
       " '자기집\\n',\n",
       " '하려고하다\\n',\n",
       " '류\\n',\n",
       " '피\\n',\n",
       " '시초\\n',\n",
       " '께서\\n',\n",
       " '설마\\n',\n",
       " '헐\\n',\n",
       " '돼\\n',\n",
       " '끠\\n',\n",
       " '해야 한다\\n',\n",
       " '힘차게\\n',\n",
       " '쉬\\n',\n",
       " 'ㅡ\\n',\n",
       " '그저\\n',\n",
       " '이때\\n',\n",
       " '어머\\n',\n",
       " '르\\n',\n",
       " '쪽으로\\n',\n",
       " '튀\\n',\n",
       " '언제부터\\n',\n",
       " '항상\\n',\n",
       " '아슬아슬\\n',\n",
       " '그렇게\\n',\n",
       " '하려고 하다\\n',\n",
       " '따라서\\n',\n",
       " '분\\n',\n",
       " '재\\n',\n",
       " '바꾸어서 한다면\\n',\n",
       " '어떠한\\n',\n",
       " '뤄\\n',\n",
       " '어떤\\n',\n",
       " '씌\\n',\n",
       " '진짜로\\n',\n",
       " '하면 된다\\n',\n",
       " '중의하나\\n',\n",
       " '뼤\\n',\n",
       " '습니까\\n',\n",
       " '다\\n',\n",
       " '마치\\n',\n",
       " '뒤따라\\n',\n",
       " '쳐\\n',\n",
       " '며\\n',\n",
       " '언젠가\\n',\n",
       " '묘\\n',\n",
       " '페\\n',\n",
       " '저더러\\n',\n",
       " '이쪽\\n',\n",
       " '껴\\n',\n",
       " '뗘\\n',\n",
       " '음\\n',\n",
       " '에\\n',\n",
       " '응당\\n',\n",
       " '다수\\n',\n",
       " '공동으로\\n',\n",
       " '안에\\n',\n",
       " '일반적으로\\n',\n",
       " '대하면\\n',\n",
       " '그 위에\\n',\n",
       " '짜\\n',\n",
       " '다음에\\n',\n",
       " '쮜\\n',\n",
       " '이렇게 많은 것\\n',\n",
       " '반대로 말하자면\\n',\n",
       " '바\\n',\n",
       " 'ㅚ\\n',\n",
       " '부터\\n',\n",
       " '어쩔 수 없다\\n',\n",
       " '줄은 몰랏다\\n',\n",
       " '일것이다\\n',\n",
       " '쁴\\n',\n",
       " '졔\\n',\n",
       " '상대적으로\\n',\n",
       " '위해서\\n',\n",
       " '얼마나\\n',\n",
       " '궈\\n',\n",
       " '렷습\\n',\n",
       " '소인\\n',\n",
       " '대로 하다\\n',\n",
       " '겸\\n',\n",
       " '푀\\n',\n",
       " '구\\n',\n",
       " '의해\\n',\n",
       " '별\\n',\n",
       " '아무도\\n',\n",
       " 'ㅠ\\n',\n",
       " '더욱\\n',\n",
       " '희\\n',\n",
       " '그러한즉\\n',\n",
       " '쎄\\n',\n",
       " '뉴\\n',\n",
       " '됨\\n',\n",
       " 'ㄴ\\n',\n",
       " '워\\n',\n",
       " '하나\\n',\n",
       " '디\\n',\n",
       " '이천팔\\n',\n",
       " '어떤것들\\n',\n",
       " '이럴정도로\\n',\n",
       " '했어요\\n',\n",
       " '냐\\n',\n",
       " '즉\\n',\n",
       " '만세\\n',\n",
       " '아주\\n',\n",
       " '같다\\n',\n",
       " '저런\\n',\n",
       " '새\\n',\n",
       " '윙윙\\n',\n",
       " '저분\\n',\n",
       " '일지라도\\n',\n",
       " '아이고\\n',\n",
       " '결코\\n',\n",
       " '제각기\\n',\n",
       " '돠\\n',\n",
       " '눈\\n',\n",
       " '반드시\\n',\n",
       " '대해 말하자면\\n',\n",
       " '다른 방면으로\\n',\n",
       " '포\\n',\n",
       " '말하자면\\n',\n",
       " '카\\n',\n",
       " '관하여\\n',\n",
       " '것으로\\n',\n",
       " '와아\\n',\n",
       " '걸\\n',\n",
       " '예\\n',\n",
       " '기준\\n',\n",
       " '켸\\n',\n",
       " '예하면\\n',\n",
       " '인젠\\n',\n",
       " '당신\\n',\n",
       " '자\\n',\n",
       " 'ㅏ\\n',\n",
       " '쨔\\n',\n",
       " '하다면\\n',\n",
       " '비\\n',\n",
       " '그에 따르는\\n',\n",
       " '꺼\\n',\n",
       " '조금\\n',\n",
       " '하지마라\\n',\n",
       " '므\\n',\n",
       " 'ㄷ\\n',\n",
       " '하는것도\\n',\n",
       " '입각하여\\n',\n",
       " '와르르\\n',\n",
       " '저리\\n',\n",
       " '하여금\\n',\n",
       " '절\\n',\n",
       " '를\\n',\n",
       " '캐\\n',\n",
       " '훠\\n',\n",
       " '이러나\\n',\n",
       " '고려하면\\n',\n",
       " '까지 미치다\\n',\n",
       " '안 그러면\\n',\n",
       " '흐흐\\n',\n",
       " '누\\n',\n",
       " '아마\\n',\n",
       " '해서는 안된다\\n',\n",
       " '쟀튼\\n',\n",
       " '않기 위해서\\n',\n",
       " '베\\n',\n",
       " '하자마자\\n',\n",
       " '그럼에도 불구하고\\n',\n",
       " '허걱\\n',\n",
       " '쩨\\n',\n",
       " '메\\n',\n",
       " '반면에\\n',\n",
       " '정확히\\n',\n",
       " '표\\n',\n",
       " '할 생각이다\\n',\n",
       " '뚝뚝\\n',\n",
       " '전부\\n',\n",
       " '하\\n',\n",
       " '나머지는\\n',\n",
       " '요만큼\\n',\n",
       " '말할것도 없고\\n',\n",
       " '들\\n',\n",
       " 'ㅓ\\n',\n",
       " '에 있다\\n',\n",
       " '인 듯하다\\n',\n",
       " '그\\n',\n",
       " '바와같이\\n',\n",
       " '마저\\n',\n",
       " '어쨋든\\n',\n",
       " '고로\\n',\n",
       " '할\\n',\n",
       " '쟈\\n',\n",
       " '뫼\\n',\n",
       " '이렇구나\\n',\n",
       " '빠\\n',\n",
       " '어김없이\\n',\n",
       " '매\\n',\n",
       " '이\\n',\n",
       " '꼬\\n',\n",
       " '쾨\\n',\n",
       " '육\\n',\n",
       " '쵸\\n',\n",
       " '얼마든지\\n',\n",
       " '에서의\\n',\n",
       " '설사\\n',\n",
       " '할 따름이다\\n',\n",
       " '댜\\n',\n",
       " '몌\\n',\n",
       " 'ㅃ\\n',\n",
       " '쩌\\n',\n",
       " '게다가\\n',\n",
       " '같이\\n',\n",
       " '키\\n',\n",
       " '레\\n',\n",
       " '숴\\n',\n",
       " '쌔\\n',\n",
       " '쎼\\n',\n",
       " '뛰\\n',\n",
       " '그사람\\n',\n",
       " '만큼\\n',\n",
       " '딱\\n',\n",
       " '한적이있다\\n',\n",
       " '애\\n',\n",
       " '의해되다\\n',\n",
       " '흠\\n',\n",
       " '비하면\\n',\n",
       " '마음대로\\n',\n",
       " '뒤이어\\n',\n",
       " '일곱\\n',\n",
       " '바꾸어 말하자면\\n',\n",
       " '곧\\n',\n",
       " '저것\\n',\n",
       " '못\\n',\n",
       " '헉\\n',\n",
       " '단지\\n',\n",
       " '앞의것\\n',\n",
       " '바와 같으니\\n',\n",
       " '따\\n',\n",
       " '휘익\\n',\n",
       " '즤\\n',\n",
       " '흑\\n',\n",
       " '쓔\\n',\n",
       " '주로\\n',\n",
       " '누구\\n',\n",
       " '총적으로 말하면\\n',\n",
       " '하는 것이 낫다\\n',\n",
       " '뿐\\n',\n",
       " '톄\\n',\n",
       " '앞\\n',\n",
       " '흔들\\n',\n",
       " '아이구\\n',\n",
       " '이유\\n',\n",
       " '관계없이\\n',\n",
       " '회\\n',\n",
       " '관한\\n',\n",
       " '대\\n',\n",
       " '혜\\n',\n",
       " '뿌\\n',\n",
       " '훨씬\\n',\n",
       " '예컨대\\n',\n",
       " '이러한\\n',\n",
       " '거의\\n',\n",
       " '외\\n',\n",
       " '로\\n',\n",
       " '머\\n',\n",
       " '셔\\n',\n",
       " '등\\n',\n",
       " '이와같다면\\n',\n",
       " '크\\n',\n",
       " '속\\n',\n",
       " '본\\n',\n",
       " '입장에서\\n',\n",
       " '너희\\n',\n",
       " '릐\\n',\n",
       " '겸사겸사\\n',\n",
       " '퉤\\n',\n",
       " '해도 된다\\n',\n",
       " '츼\\n',\n",
       " '이가\\n',\n",
       " '뮤\\n',\n",
       " '일때\\n',\n",
       " '하더라도\\n',\n",
       " '찌\\n',\n",
       " '태\\n',\n",
       " '지지\\n',\n",
       " '그러니\\n',\n",
       " '이 밖에\\n',\n",
       " 'ㅜ\\n',\n",
       " '갸\\n',\n",
       " '된 이상\\n',\n",
       " '그런\\n',\n",
       " '하고 있었다\\n',\n",
       " '뢰\\n',\n",
       " '기 위해\\n',\n",
       " '뿐이다\\n',\n",
       " '하는것만 못하다\\n',\n",
       " '정말\\n',\n",
       " '남\\n',\n",
       " '쑈\\n',\n",
       " '불구하고\\n',\n",
       " '미\\n',\n",
       " '뺘\\n',\n",
       " '비길수 없다\\n',\n",
       " '하기 때문에\\n',\n",
       " '배\\n',\n",
       " '아니나다를가\\n',\n",
       " '시간\\n',\n",
       " '건\\n',\n",
       " '어느 쪽\\n',\n",
       " '가\\n',\n",
       " '롸\\n',\n",
       " '과연\\n',\n",
       " '저기\\n',\n",
       " '하는 것만 못하다\\n',\n",
       " '쯰\\n',\n",
       " '아무거나\\n',\n",
       " '대체로\\n',\n",
       " '예를 들자면\\n',\n",
       " '어찌됏든\\n',\n",
       " '큐\\n',\n",
       " '가끔\\n',\n",
       " 'ㅍ\\n',\n",
       " '써\\n',\n",
       " '였다\\n',\n",
       " '노\\n',\n",
       " '쇠\\n',\n",
       " '메쓰겁다\\n',\n",
       " '할망정\\n',\n",
       " '쏘\\n',\n",
       " '도착하다\\n',\n",
       " '관해서는\\n',\n",
       " '기타\\n',\n",
       " '에 한하다\\n',\n",
       " '있는\\n',\n",
       " '더군다나\\n',\n",
       " '하고있었다\\n',\n",
       " '향해서\\n',\n",
       " '상\\n',\n",
       " '폐\\n',\n",
       " '로부터\\n',\n",
       " '보다더\\n',\n",
       " '약간\\n',\n",
       " '이르기까지\\n',\n",
       " '그치지\\n',\n",
       " '움\\n',\n",
       " '인가\\n',\n",
       " '그들의\\n',\n",
       " '방금\\n',\n",
       " '줘\\n',\n",
       " '중에서\\n',\n",
       " '이렇게 되면\\n',\n",
       " '뇨\\n',\n",
       " '한 후\\n',\n",
       " '앞에서\\n',\n",
       " 'ㄲ\\n',\n",
       " '엿튼\\n',\n",
       " '그렇게 함으로써\\n',\n",
       " '아이쿠\\n',\n",
       " '여보시오\\n',\n",
       " 'ㅂ\\n',\n",
       " '구토하다\\n',\n",
       " '임\\n',\n",
       " '인\\n',\n",
       " 'ㅗ\\n',\n",
       " '봐\\n',\n",
       " '투\\n',\n",
       " '더라도\\n',\n",
       " '하곤하였다\\n',\n",
       " '견지에서\\n',\n",
       " '녜\\n',\n",
       " '결과에 이르다\\n',\n",
       " '이래\\n',\n",
       " '할지언정\\n',\n",
       " '허허\\n',\n",
       " '평\\n',\n",
       " '후\\n',\n",
       " '어느 것\\n',\n",
       " '다른\\n',\n",
       " '실로\\n',\n",
       " '켜\\n',\n",
       " '하다\\n',\n",
       " '어찌\\n',\n",
       " '개\\n',\n",
       " '또\\n',\n",
       " '안\\n',\n",
       " '츄\\n',\n",
       " '의지하여\\n',\n",
       " '그리하여\\n',\n",
       " '이것\\n',\n",
       " '의\\n',\n",
       " '혼자\\n',\n",
       " '치\\n',\n",
       " '하여야\\n',\n",
       " '않기 위하여\\n',\n",
       " '하구나\\n',\n",
       " '으로 인하여\\n',\n",
       " '알 수 있다\\n',\n",
       " '이번\\n',\n",
       " '해요\\n',\n",
       " '빠르게\\n',\n",
       " '때가 되어\\n',\n",
       " '쳇\\n',\n",
       " '이러이러하다\\n',\n",
       " '우에 종합한것과같이\\n',\n",
       " '말할 것도 없고\\n',\n",
       " '츠\\n',\n",
       " '뷰\\n',\n",
       " '하도다\\n',\n",
       " '교\\n',\n",
       " '풔\\n',\n",
       " '꽈\\n',\n",
       " '든간에\\n',\n",
       " '막론하고\\n',\n",
       " '무릎쓰고\\n',\n",
       " '오\\n',\n",
       " '갈\\n',\n",
       " '들에게\\n',\n",
       " '비걱거리다\\n',\n",
       " '뵤\\n',\n",
       " '으악\\n',\n",
       " '롭\\n',\n",
       " '그녀\\n',\n",
       " '꾀\\n',\n",
       " '또한\\n',\n",
       " '어찌됏어\\n',\n",
       " '적\\n',\n",
       " '하지마\\n',\n",
       " '어디\\n',\n",
       " '까요\\n',\n",
       " '셰\\n',\n",
       " '작\\n',\n",
       " '그런데\\n',\n",
       " '과\\n',\n",
       " '밖에 안된다\\n',\n",
       " '아홉\\n',\n",
       " '긔\\n',\n",
       " '할뿐\\n',\n",
       " '무엇\\n',\n",
       " '령\\n',\n",
       " '하면 할수록\\n',\n",
       " '악\\n',\n",
       " '이와 같다면\\n',\n",
       " '까지\\n',\n",
       " '촤\\n',\n",
       " '우와\\n',\n",
       " '눠\\n',\n",
       " '후에\\n',\n",
       " '무렵\\n',\n",
       " '띄\\n',\n",
       " '뫄\\n',\n",
       " '아니었다면\\n',\n",
       " '조차도\\n',\n",
       " '삐걱\\n',\n",
       " '연관되다\\n',\n",
       " '됴\\n',\n",
       " '쒀\\n',\n",
       " '위에서 서술한바와같이\\n',\n",
       " '어때\\n',\n",
       " '뾰\\n',\n",
       " '브\\n',\n",
       " '불문하고\\n',\n",
       " '어\\n',\n",
       " '하지 않는다면\\n',\n",
       " '에서는\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(stop_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    wordlist = f.readlines()\n",
    "\n",
    "wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193 1193\n",
      "['만일', '상대적으로 말하자면', '더구나', '붕붕', '바꾸어말하면', '주룩주룩', '한항목', '예를 들면', '아야', '지금']\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "\n",
    "for word in wordlist :\n",
    "    stopwords.append(word.replace(\"\\n\", \"\"))\n",
    "print(len(wordlist), len(stopwords))\n",
    "print(stopwords[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "counter = Counter()\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_tokens \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mmorphs(review) \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m X_train]\n\u001b[0;32m      2\u001b[0m test_tokens \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mmorphs(review) \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m X_test]\n",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_tokens \u001b[38;5;241m=\u001b[39m [\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m X_train]\n\u001b[0;32m      2\u001b[0m test_tokens \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mmorphs(review) \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m X_test]\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\konlpy\\tag\\_okt.py:89\u001b[0m, in \u001b[0;36mOkt.morphs\u001b[1;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmorphs\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\hwans\\anaconda3\\envs\\NLP_018_230_38\\lib\\site-packages\\konlpy\\tag\\_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[1;32m---> 71\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjki\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_tokens = [tokenizer.morphs(review) for review in X_train]\n",
    "test_tokens = [tokenizer.morphs(review) for review in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_tokens), len(test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(corpus, n_vocab, special_tokens) :\n",
    "    counter = Counter()\n",
    "    for tokens in corpus :\n",
    "        counter.update(tokens)\n",
    "    vocab = special_tokens\n",
    "    for token, count in counter.most_common(n_vocab) :\n",
    "        vocab.append(token)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(corpus = train_tokens, n_vocab = 20000, special_tokens = [\"<PAD>\", \"<UNK>\"])\n",
    "token_to_id = {token:idx for idx, token in enumerate(vocab)}\n",
    "id_to_token = {idx:token for idx, token in enumerate(vocab)}\n",
    "\n",
    "print(vocab[:20])\n",
    "print(len(vocab))\n",
    "\n",
    "print(token_to_id)\n",
    "print(id_to_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정수 인코딩 및 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_length, pad_value) :\n",
    "    result = list()\n",
    "    for sequence in sequences :\n",
    "        sequence = sequence[:max_length]\n",
    "        pad_length = max_length - len(sequence)\n",
    "        padded_sequence = sequence + [pad_value] * pad_length\n",
    "        result.append(padded_sequence)\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_id = token_to_id['<UNK>']\n",
    "train_ids = [[token_to_id.get(token, unk_id)for token in text] for text in train_tokens]\n",
    "test_ids = [[token_to_id.get(token, unk_id)for token in text] for text in test_tokens]\n",
    "\n",
    "max_length = 200\n",
    "pad_id = token_to_id[\"<PAD>\"]\n",
    "train_ids = pad_sequences(train_ids, max_length, pad_id)\n",
    "test_ids = pad_sequences(test_ids, max_length, pad_id)\n",
    "\n",
    "print(train_ids[0])\n",
    "print(test_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_ids = torch.tensor(train_ids)\n",
    "test_ids = torch.tensor(test_ids)\n",
    "\n",
    "train_labels = torch.tensor(X_train.label.values, dtype = torch.float32)\n",
    "test_labels = torch.tensor(X_test.label.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_ids, train_labels)\n",
    "test_dataset = TensorDataset(test_ids, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# SentenceClassifier 정의\n",
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, n_layers, dropout=0.5, bidirectional=True, model_type=\"lstm\", pretrained_embedding=None):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        if pretrained_embedding is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.tensor(pretrained_embedding, dtype=torch.float32),\n",
    "                padding_idx=0\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                num_embeddings=n_vocab,\n",
    "                embedding_dim=embedding_dim,\n",
    "                padding_idx=0\n",
    "            )\n",
    "        \n",
    "        # LSTM 모델 사용\n",
    "        self.model = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Bidirectional 설정에 따른 분류기\n",
    "        if bidirectional:\n",
    "            self.classifier = nn.Linear(hidden_dim * 2, 1)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Embedding lookup\n",
    "        embeddings = self.embedding(inputs)\n",
    "        \n",
    "        # LSTM 모델에 입력\n",
    "        output, _ = self.model(embeddings)\n",
    "        \n",
    "        # 마지막 시퀀스 출력 사용\n",
    "        last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        \n",
    "        # 로짓 계산\n",
    "        logits = self.classifier(last_output)\n",
    "        return logits\n",
    "\n",
    "# 모델 초기화\n",
    "n_vocab = len(token_to_id)  # 사전 크기\n",
    "hidden_dim = 674  # LSTM 은닉층 크기\n",
    "embedding_dim = 128  # Embedding 차원\n",
    "n_layers = 2  # LSTM 레이어 수\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "classifier = SentenceClassifier(\n",
    "    n_vocab=n_vocab, hidden_dim=hidden_dim, embedding_dim=embedding_dim, n_layers=n_layers\n",
    ").to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)  # 이진 분류 손실 함수\n",
    "optimizer = optim.RMSprop(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train(model, datasets, criterion, optimizer, device, interval):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for step, (input_ids, labels) in enumerate(datasets):\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1)  # 이진 분류이므로 차원 추가\n",
    "\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % interval == 0:\n",
    "            print(f\"Train Loss {step}: {np.mean(losses)}\")\n",
    "\n",
    "# 테스트 함수 정의\n",
    "def test(model, datasets, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    corrects = []\n",
    "\n",
    "    with torch.no_grad():  # 테스트에서는 그래디언트 계산 안함\n",
    "        for step, (input_ids, labels) in enumerate(datasets):\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            yhat = torch.sigmoid(logits) > 0.5  # Sigmoid로 이진 분류\n",
    "            corrects.extend(torch.eq(yhat, labels).cpu().tolist())\n",
    "\n",
    "    print(f\"Val Loss: {np.mean(losses)}, Val Accuracy: {np.mean(corrects)}\")\n",
    "\n",
    "# 학습 설정\n",
    "epochs = 5\n",
    "interval = 500  # 500번마다 출력\n",
    "\n",
    "# 학습 및 테스트 반복\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train(classifier, train_loader, criterion, optimizer, device, interval)\n",
    "    test(classifier, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# train_ids 및 test_ids는 이미 존재한다고 가정합니다.\n",
    "train_ids = torch.tensor(train_ids)\n",
    "test_ids = torch.tensor(test_ids)\n",
    "\n",
    "# label 열이 'label'이라는 이름으로 존재한다고 가정하여 수정\n",
    "train_labels = torch.tensor(trainDF.loc[X_train.index, 'label'].values, dtype=torch.float32)\n",
    "test_labels = torch.tensor(trainDF.loc[X_test.index, 'label'].values, dtype=torch.float32)\n",
    "\n",
    "# TensorDataset을 사용해 데이터셋 구성\n",
    "train_dataset = TensorDataset(train_ids, train_labels)\n",
    "test_dataset = TensorDataset(test_ids, test_labels)\n",
    "\n",
    "# DataLoader를 사용해 배치 데이터 구성\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, n_layers, dropout=0.5, bidirectional=True, model_type=\"lstm\", pretrained_embedding=None):\n",
    "        super().__init__()\n",
    "        if pretrained_embedding is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.tensor(pretrained_embedding, dtype=torch.float32),\n",
    "                padding_idx=0\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                num_embeddings=n_vocab,\n",
    "                embedding_dim=embedding_dim,\n",
    "                padding_idx=0\n",
    "            )\n",
    "        \n",
    "        # LSTM 모델 사용\n",
    "        self.model = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        if bidirectional:\n",
    "            self.classifier = nn.Linear(hidden_dim * 2, 1)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        output, _ = self.model(embeddings)\n",
    "        last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        logits = self.classifier(last_output)\n",
    "        return logits\n",
    "\n",
    "# 모델 초기화\n",
    "n_vocab = len(token_to_id)  # 사전 크기\n",
    "hidden_dim = 674  # LSTM 은닉층 크기\n",
    "embedding_dim = 128  # Embedding 차원\n",
    "n_layers = 2  # LSTM 레이어 수\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "classifier = SentenceClassifier(\n",
    "    n_vocab=n_vocab, hidden_dim=hidden_dim, embedding_dim=embedding_dim, n_layers=n_layers\n",
    ").to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.RMSprop(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 저장을 위한 경로\n",
    "SAVE_FILE = \"best_model_state_dict.pth\"\n",
    "SAVE_MODEL = \"best_model.pth\"\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# 학습 함수 정의\n",
    "# 학습 함수 정의 (Train 정확도 추가)\n",
    "def train(model, datasets, criterion, optimizer, device, interval):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    corrects = []\n",
    "\n",
    "    for step, (input_ids, labels) in enumerate(datasets):\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "\n",
    "        logits = model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # 예측값 계산 (sigmoid로 확률화하고 0.5를 기준으로 이진 분류)\n",
    "        predictions = torch.sigmoid(logits) > 0.5\n",
    "        corrects.extend(torch.eq(predictions, labels).cpu().tolist())  # 정답과 예측 비교\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % interval == 0:\n",
    "            train_loss = np.mean(losses)  # 현재까지의 평균 손실 계산\n",
    "            train_accuracy = np.mean(corrects)  # 현재까지의 평균 정확도 계산\n",
    "            print(f\"Train Step {step}: Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# 테스트 함수 정의\n",
    "def test(model, datasets, criterion, device):\n",
    "    global best_val_loss  # 전역 변수로 설정하여 저장 기준으로 사용\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    corrects = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (input_ids, labels) in enumerate(datasets):\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            yhat = torch.sigmoid(logits) > 0.5\n",
    "            corrects.extend(torch.eq(yhat, labels).cpu().tolist())\n",
    "\n",
    "    val_loss = np.mean(losses)\n",
    "    val_accuracy = np.mean(corrects)\n",
    "\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # 가장 좋은 성능일 때 모델 저장\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), SAVE_FILE)  # state_dict 저장\n",
    "        torch.save(model, SAVE_MODEL)  # 전체 모델 저장\n",
    "        print(f\"Best model saved with loss: {val_loss:.4f}\")\n",
    "\n",
    "# 학습 설정\n",
    "epochs = 5\n",
    "interval = 500\n",
    "\n",
    "# 학습 및 테스트 반복\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train(classifier, train_loader, criterion, optimizer, device, interval)\n",
    "    test(classifier, test_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_018_230_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
